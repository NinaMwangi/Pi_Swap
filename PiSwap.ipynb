{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinaMwangi/Pi_Swap/blob/main/PiSwap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujuLMxSvoXbg"
      },
      "source": [
        "# Optimization Techniques in Machine Learning\n",
        "\n",
        "Objective: This assignment aims to explore implementation or Machine Learning Models with regularization, optimization and Error analysisÂ  techniques used in machine learning to improve models' performance, convergence speed, and efficiency..\n",
        "\n",
        "A Notebook detailing the following\n",
        "\n",
        "* Project name\n",
        "* Clear out puts from cells\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "1. Acquire a dataset suitable for ML tasks as per your proposal.\n",
        "2. Implement a simple machine learning model based on neural networks on the chosen dataset without any defined optimization techniques. (Check instructions)\n",
        "3. Implement and compare the model's performance after applying 3 to 4 disntict combinations regularization and optimization techniques.\n",
        "4. Discuss the results on the README file.\n",
        "5. Make predictions using test data\n",
        "7. Implement error analysis techniques and ensure there is: F1-Score, Recall, Precision, RUC a confusion matrix using plotting libraries (not verbose)\n",
        "\n",
        "Submit notebook to github repo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vXxWhmmR7xI",
        "outputId": "0b27181a-6abc-49c3-9129-0f654a5fd2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tL2aruSFoG",
        "outputId": "b49f878b-b1dd-4cdd-e917-16552c695b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8VW_IzbI3od"
      },
      "source": [
        "\n",
        "# Case Study and Implementation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGCnpzs9M4Fd"
      },
      "outputs": [],
      "source": [
        "#Import Necessary Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit, StratifiedKFold,StratifiedShuffleSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1FN7bFeIxfH"
      },
      "source": [
        "# The Dataset\n",
        "> My dataset contains a list of secondhand books from the pre-primary level all the way to the tertiary level. With the high cost of living I would like to create a model that will be used to recommend the right second hand books to the user based on different factors that are both user based and item based, to allow easier accessibility to fair priced good quality second hand books. The data contains the following columns. isbn, book_id, User_id, title, author, unit_price, unit_price_vat, level, subject, description, condition, purchase_intent, previous_purchase,rating, clicks, wishlist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "nas-T7xwPIso",
        "outputId": "5c090446-64d3-4a3b-e3be-9778e75e1222"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                isbn  book_id  User_id  \\\n",
              "0  978-9966-65-190-7        1     1176   \n",
              "1  978-9966-65-191-4        2     1031   \n",
              "2  978-9966-65-185-3        3     1010   \n",
              "3  978-9966-65-184-6        4     1051   \n",
              "4  978-9966-65-188-4        5     1158   \n",
              "\n",
              "                                               title            author  \\\n",
              "0      KLB Skillgrow Mathematical Activities L/B PP1   J. Mbugua et al   \n",
              "1      KLB Skillgrow Mathematical Activities T/G PP1   J. Mbugua et al   \n",
              "2  KLB Skillgrow Language Activities(English) L/B...  G. Wambiri et al   \n",
              "3  KLB Skillgrow Language Activities(English) T/G...  G. Wambiri et al   \n",
              "4         KLB Skillgrow Kiswahili Activities L/B PP1  S. Wandera et al   \n",
              "\n",
              "  unit_price unit_price_vat level                  subject  \\\n",
              "0        240            279   PP1  Mathematical Activities   \n",
              "1        340            395   PP1  Mathematical Activities   \n",
              "2        345            401   PP1       English Activities   \n",
              "3        382            444   PP1       English Activities   \n",
              "4        240            279   PP1     Kiswahili Activities   \n",
              "\n",
              "                                         description condition  \\\n",
              "0  KLB Skillgrow Mathematical Activities L/B PP1,...      Fair   \n",
              "1  KLB Skillgrow Mathematical Activities T/G PP1,...      Fair   \n",
              "2  KLB Skillgrow Language Activities(English) L/B...      Fair   \n",
              "3  KLB Skillgrow Language Activities(English) T/G...      Fair   \n",
              "4  KLB Skillgrow Kiswahili Activities L/B PP1,S. ...      Fair   \n",
              "\n",
              "   purchase_intent  previous_purchase  rating  clicks  wishlist  \n",
              "0                0                0.0     2.0     8.0       0.0  \n",
              "1                0                0.0     2.0     8.0       1.0  \n",
              "2                0                0.0     1.0     7.0       1.0  \n",
              "3                0                1.0     3.0     7.0       1.0  \n",
              "4                0                0.0     5.0     1.0       1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5825c55-1f16-48ad-8a76-6f391c1fbcb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isbn</th>\n",
              "      <th>book_id</th>\n",
              "      <th>User_id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>unit_price</th>\n",
              "      <th>unit_price_vat</th>\n",
              "      <th>level</th>\n",
              "      <th>subject</th>\n",
              "      <th>description</th>\n",
              "      <th>condition</th>\n",
              "      <th>purchase_intent</th>\n",
              "      <th>previous_purchase</th>\n",
              "      <th>rating</th>\n",
              "      <th>clicks</th>\n",
              "      <th>wishlist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>978-9966-65-190-7</td>\n",
              "      <td>1</td>\n",
              "      <td>1176</td>\n",
              "      <td>KLB Skillgrow Mathematical Activities L/B PP1</td>\n",
              "      <td>J. Mbugua et al</td>\n",
              "      <td>240</td>\n",
              "      <td>279</td>\n",
              "      <td>PP1</td>\n",
              "      <td>Mathematical Activities</td>\n",
              "      <td>KLB Skillgrow Mathematical Activities L/B PP1,...</td>\n",
              "      <td>Fair</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>978-9966-65-191-4</td>\n",
              "      <td>2</td>\n",
              "      <td>1031</td>\n",
              "      <td>KLB Skillgrow Mathematical Activities T/G PP1</td>\n",
              "      <td>J. Mbugua et al</td>\n",
              "      <td>340</td>\n",
              "      <td>395</td>\n",
              "      <td>PP1</td>\n",
              "      <td>Mathematical Activities</td>\n",
              "      <td>KLB Skillgrow Mathematical Activities T/G PP1,...</td>\n",
              "      <td>Fair</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>978-9966-65-185-3</td>\n",
              "      <td>3</td>\n",
              "      <td>1010</td>\n",
              "      <td>KLB Skillgrow Language Activities(English) L/B...</td>\n",
              "      <td>G. Wambiri et al</td>\n",
              "      <td>345</td>\n",
              "      <td>401</td>\n",
              "      <td>PP1</td>\n",
              "      <td>English Activities</td>\n",
              "      <td>KLB Skillgrow Language Activities(English) L/B...</td>\n",
              "      <td>Fair</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>978-9966-65-184-6</td>\n",
              "      <td>4</td>\n",
              "      <td>1051</td>\n",
              "      <td>KLB Skillgrow Language Activities(English) T/G...</td>\n",
              "      <td>G. Wambiri et al</td>\n",
              "      <td>382</td>\n",
              "      <td>444</td>\n",
              "      <td>PP1</td>\n",
              "      <td>English Activities</td>\n",
              "      <td>KLB Skillgrow Language Activities(English) T/G...</td>\n",
              "      <td>Fair</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>978-9966-65-188-4</td>\n",
              "      <td>5</td>\n",
              "      <td>1158</td>\n",
              "      <td>KLB Skillgrow Kiswahili Activities L/B PP1</td>\n",
              "      <td>S. Wandera et al</td>\n",
              "      <td>240</td>\n",
              "      <td>279</td>\n",
              "      <td>PP1</td>\n",
              "      <td>Kiswahili Activities</td>\n",
              "      <td>KLB Skillgrow Kiswahili Activities L/B PP1,S. ...</td>\n",
              "      <td>Fair</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5825c55-1f16-48ad-8a76-6f391c1fbcb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5825c55-1f16-48ad-8a76-6f391c1fbcb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5825c55-1f16-48ad-8a76-6f391c1fbcb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-379701d2-d333-4e31-856b-7c9963e9f5ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-379701d2-d333-4e31-856b-7c9963e9f5ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-379701d2-d333-4e31-856b-7c9963e9f5ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1013,\n  \"fields\": [\n    {\n      \"column\": \"isbn\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 793,\n        \"samples\": [\n          \"978-9966-65-661-2\",\n          \"978-9966-65-316-1\",\n          \"9966-10-513-4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"book_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 292,\n        \"min\": 1,\n        \"max\": 1013,\n        \"num_unique_values\": 1013,\n        \"samples\": [\n          690,\n          519,\n          941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58,\n        \"min\": 1001,\n        \"max\": 1200,\n        \"num_unique_values\": 197,\n        \"samples\": [\n          1033,\n          1072,\n          1166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 991,\n        \"samples\": [\n          \"KLB TopScholar Pre-Technical and Pre-Career Grade 7 L/B\",\n          \"Kuti Makes a Difference\",\n          \"Kisa Cha Mrina Asali Na Wenzake\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 476,\n        \"samples\": [\n          \"H.A. Skinner\",\n          \"M. Omar et al\",\n          \"P. Mwangi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unit_price\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 290,\n        \"samples\": [\n          \"171\",\n          \"611\",\n          \"445\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unit_price_vat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 287,\n        \"samples\": [\n          \"418\",\n          \"709\",\n          \"180\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"PP1\",\n          \"Form 2\",\n          \"Grade 6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 84,\n        \"samples\": [\n          \"Medical Sciences\",\n          \"Mathematical Activities\",\n          \"Computer studies\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1010,\n        \"samples\": [\n          \"Inventor Business Studies Form 3 T/G,M.Mungiria et al,Form 3\",\n          \"Words Of My Groaning,C.L.P. Chong,Secondary Level\",\n          \"Top Mark KCSE Revision Physics,B.K. Okoth,Revision Series\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"condition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"New\",\n          \"Good\",\n          \"Fair\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"purchase_intent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous_purchase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5001861515337904,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.411634411493185,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clicks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.9248026378664447,\n        \"min\": 0.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wishlist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5000540511325308,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#TO DO: Load Data (Seprate into: Train, Validation and test sets)\n",
        "#Importing dataset and defining columns.\n",
        "data = pd.read_csv('/content/drive/MyDrive/Summative Intro 2 ML/PiSwap Data - Sheet1.csv')\n",
        "columns = ['isbn', 'book_id', 'User_id', 'title', 'author', 'unit_price', 'unit_price_vat', 'level', 'subject', 'description', 'condition', 'purchase_intent', 'previous_purchase', 'rating', 'clicks', 'wishlist']\n",
        "data.columns = columns\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR4BNYoUMzMP"
      },
      "source": [
        "#Task: Define a function that creates models without and With specified Optimization techniques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGtPmYb_SDHy"
      },
      "outputs": [],
      "source": [
        "def clean_title(title):\n",
        "  return unidecode.unidecode(title.lower().strip())\n",
        "\n",
        "#Cleaning titles and removing inconsistencies\n",
        "data[\"title\"] = data[\"title\"].apply(clean_title)\n",
        "\n",
        "#Removing duplicates\n",
        "data = data.drop_duplicates(subset=[\"title\"])\n",
        "\n",
        "#Removing duplicate user-book interactions (if ratings exist)\n",
        "data = data.drop_duplicates(subset=[\"User_id\", \"title\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B6Jtz7AUlE-"
      },
      "outputs": [],
      "source": [
        "#Use StratifiedShuffleSplit to ensure overlap\n",
        "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Getting the value counts of 'User_id'\n",
        "user_counts = data['User_id'].value_counts()\n",
        "\n",
        "# Filtering out users with only one occurrence\n",
        "valid_users = user_counts[user_counts > 1].index\n",
        "\n",
        "# Filter the data to include only valid users\n",
        "filtered_data = data[data['User_id'].isin(valid_users)]\n",
        "\n",
        "# performing the split on the filtered data\n",
        "for train_indices, test_indices in splitter.split(filtered_data, filtered_data[\"User_id\"]):\n",
        "    train_data = filtered_data.iloc[train_indices]\n",
        "    test_data = filtered_data.iloc[test_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBvapMEWXaC9",
        "outputId": "d07f47e1-f986-4c62-d9c4-b60ca87c8eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No missing users to add.\n",
            " Users with all zero ratings: 0\n",
            " No zero-rated users found. Skipping replacement.\n"
          ]
        }
      ],
      "source": [
        "# Creating rating matrix from updated train data\n",
        "train_rating_matrix = train_data.pivot_table(values=\"rating\", index=\"User_id\", columns=\"title\")\n",
        "test_rating_matrix = test_data.pivot_table(values=\"rating\", index=\"User_id\", columns=\"title\")\n",
        "\n",
        "# Ensuring test data has valid users\n",
        "test_data = test_data[test_data[\"User_id\"].isin(train_rating_matrix.index)]\n",
        "# Ensuring test users exist in train_data\n",
        "test_data = test_data[test_data[\"User_id\"].isin(train_data[\"User_id\"])]\n",
        "\n",
        "# Filling missing values with each book's average rating\n",
        "train_rating_matrix = train_rating_matrix.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
        "\n",
        "# Ensuring item overlap between train and test sets\n",
        "train_items = train_rating_matrix.columns\n",
        "test_rating_matrix = test_rating_matrix.loc[:, test_rating_matrix.columns.isin(train_items)]\n",
        "\n",
        "# Compute cosine similarity\n",
        "item_similarity = cosine_similarity(train_rating_matrix.T)\n",
        "\n",
        "# Build similarity dataframe\n",
        "item_similarity_df = pd.DataFrame(item_similarity,\n",
        "                                  index=train_rating_matrix.columns,\n",
        "                                  columns=train_rating_matrix.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_books(user_id, num_recommendations=5):\n",
        "    if user_id not in train_rating_matrix.index:\n",
        "        most_popular = train_rating_matrix.count().sort_values(ascending=False).index[:num_recommendations]\n",
        "        return list(most_popular)\n",
        "\n",
        "    # Get user ratings\n",
        "    user_ratings = train_rating_matrix.loc[user_id]\n",
        "    rated_items = user_ratings[user_ratings > 0].index\n",
        "\n",
        "    if len(rated_items) == 0:\n",
        "        most_popular = train_rating_matrix.count().sort_values(ascending=False).index[:num_recommendations]\n",
        "        return list(most_popular)\n",
        "\n",
        "    # Store similar books\n",
        "    similar_items = {}\n",
        "    for item in rated_items:\n",
        "        if item in item_similarity_df.index:\n",
        "            similar_scores = item_similarity_df[item]\n",
        "            similar_items[item] = similar_scores.drop(item)\n",
        "        else:\n",
        "            print(f\" Item '{item}' not found in similarity matrix.\")\n",
        "\n",
        "    # Compute weighted scores\n",
        "    weighted_scores = {}\n",
        "    for item, similar in similar_items.items():\n",
        "        for similar_item, score in similar.items():\n",
        "            weighted_scores.setdefault(similar_item, 0)\n",
        "            weighted_scores[similar_item] += score * user_ratings[item]\n",
        "\n",
        "    # Return top recommended books\n",
        "    if weighted_scores:\n",
        "        recommendations = sorted(weighted_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
        "        recommended_items = [item for item, score in recommendations]\n",
        "        return recommended_items\n",
        "    else:\n",
        "        most_popular = train_rating_matrix.count().sort_values(ascending=False).index[:num_recommendations]\n",
        "        return list(most_popular)"
      ],
      "metadata": {
        "id": "c8CqRY5A1T9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ9OXp1TSaXn"
      },
      "source": [
        "# Task: Evaluating the model using RMSE, Precision@K, Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkihQBsaUxGh",
        "outputId": "4f233042-80dd-4fcd-992c-eda5e32710cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **Evaluation Results:**\n",
            " **Average RMSE:** 0.0000\n",
            " **Average Precision@K:** 0.0023\n",
            " **Average Recall@K:** 0.0116\n"
          ]
        }
      ],
      "source": [
        "# RMSE Calculation\n",
        "def calculate_rmse(predictions, actuals):\n",
        "    predictions = np.array(predictions)\n",
        "    actuals = np.array(actuals)\n",
        "\n",
        "    # Filter out NaN values\n",
        "    valid_indices = ~np.isnan(predictions) & ~np.isnan(actuals)\n",
        "    predictions = predictions[valid_indices]\n",
        "    actuals = actuals[valid_indices]\n",
        "\n",
        "    if actuals.size > 0:\n",
        "        return np.sqrt(mean_squared_error(actuals, predictions))\n",
        "    return 0\n",
        "\n",
        "# Precision@K Calculation\n",
        "def calculate_precision_at_k(predictions, actuals, k=5):\n",
        "    if len(actuals) == 0 or len(predictions) == 0:\n",
        "        return 0.0\n",
        "    intersection = np.intersect1d(predictions, actuals)\n",
        "    return len(intersection) / min(k, len(predictions))\n",
        "\n",
        "# Recall@K Calculation\n",
        "def calculate_recall_at_k(predictions, actuals, k=5):\n",
        "    if len(actuals) == 0 or len(predictions) == 0:\n",
        "        return 0.0\n",
        "    intersection = np.intersect1d(predictions, actuals)\n",
        "    return len(intersection) / len(actuals)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "def evaluate_predictions(test_rating_matrix, item_similarity_df, train_rating_matrix, k=5):\n",
        "    rmse_scores = []\n",
        "    precision_at_k_scores = []\n",
        "    recall_at_k_scores = []\n",
        "\n",
        "    for user_id in test_rating_matrix.index:\n",
        "        user_test_ratings = test_rating_matrix.loc[user_id].dropna()\n",
        "        if user_test_ratings.empty:\n",
        "            continue\n",
        "\n",
        "        actual_items = user_test_ratings[user_test_ratings > 0].index.tolist()\n",
        "        predicted_items = recommend_books(user_id)\n",
        "\n",
        "        if isinstance(predicted_items, str) or len(predicted_items) == 0:\n",
        "            continue\n",
        "\n",
        "        # RMSE Calculation (for rating prediction)\n",
        "\n",
        "        for item in actual_items:\n",
        "          try:\n",
        "            predicted_rating = predict_rating(user_id, item, item_similarity_df, train_rating_matrix)\n",
        "            predicted_ratings = np.array(predicted_ratings)\n",
        "          except KeyError:\n",
        "            pass\n",
        "\n",
        "        # Precision@K Calculation\n",
        "        precision_at_k = calculate_precision_at_k(predicted_items, actual_items, k)\n",
        "        if not np.isnan(precision_at_k):\n",
        "            precision_at_k_scores.append(precision_at_k)\n",
        "\n",
        "        # Recall@K Calculation\n",
        "        recall_at_k = calculate_recall_at_k(predicted_items, actual_items, k)\n",
        "        if not np.isnan(recall_at_k):\n",
        "            recall_at_k_scores.append(recall_at_k)\n",
        "\n",
        "    # Compute Averages\n",
        "    avg_rmse = np.mean(rmse_scores) if rmse_scores else 0\n",
        "    avg_precision_at_k = np.mean(precision_at_k_scores) if precision_at_k_scores else 0\n",
        "    avg_recall_at_k = np.mean(recall_at_k_scores) if recall_at_k_scores else 0\n",
        "\n",
        "    return avg_rmse, avg_precision_at_k, avg_recall_at_k"
      ],
      "metadata": {
        "id": "Y1wXWgpO1pqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Rating Function\n",
        "def predict_rating(user_id, item_id, item_similarity_df, train_rating_matrix):\n",
        "\n",
        "    if user_id not in train_rating_matrix.index:\n",
        "        return train_rating_matrix.stack().mean()\n",
        "\n",
        "    if item_id not in train_rating_matrix.columns:\n",
        "        return train_rating_matrix.stack().mean()\n",
        "\n",
        "    user_ratings = train_rating_matrix.loc[user_id]\n",
        "\n",
        "    # If all user ratings are zero, return mean rating\n",
        "    if user_ratings.sum() == 0:\n",
        "        return train_rating_matrix.stack().mean()\n",
        "\n",
        "    # Compute similarity-based rating\n",
        "    rated_items = user_ratings[user_ratings > 0].index\n",
        "\n",
        "    if rated_items.empty:\n",
        "        return train_rating_matrix.stack().mean()\n",
        "\n",
        "        similar_items = {}\n",
        "        for rated_item in rated_items:\n",
        "            if rated_item in item_similarity_df.index:\n",
        "                similar_scores = item_similarity_df[rated_item]\n",
        "                similar_items[rated_item] = similar_scores.drop(rated_item)\n",
        "\n",
        "        weighted_scores = {}\n",
        "        for rated_item, similar in similar_items.items():\n",
        "            for similar_item, score in similar.items():\n",
        "                if similar_item == item_id:\n",
        "                    weighted_scores.setdefault(similar_item, 0)\n",
        "                    weighted_scores[similar_item] += score * user_ratings[rated_item]\n",
        "\n",
        "        if weighted_scores:\n",
        "            return np.mean(list(weighted_scores.values()))\n",
        "        else:\n",
        "          return train_rating_matrix[item_id].mean() if item_id in train_rating_matrix else train_rating_matrix.stack().mean()\n",
        "\n",
        "\n",
        "    return train_rating_matrix.stack().mean()"
      ],
      "metadata": {
        "id": "HtDVCnlL10ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hc6k2taT0_n"
      },
      "source": [
        "# SECTION 2: Optimization and Regularization Combinations\n",
        "Using Pearson Correlation instead of cosine similarity and adjusting Top K to 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr6HuVEtXvoP",
        "outputId": "8152de36-86bd-4c4f-c524-84d7dd5a8732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **Evaluation Results (Using Pearson Correlation & K=10):**\n",
            " **Average RMSE:** 0.0000\n",
            " **Average Precision@K:** 0.0023\n",
            " **Average Recall@K:** 0.0116\n"
          ]
        }
      ],
      "source": [
        "# Use Pearson Correlation Instead of Cosine Similarity\n",
        "item_similarity_df_pearson = train_rating_matrix.T.corr(method=\"pearson\").fillna(0)\n",
        "\n",
        "# Apply Weighting Based on Rating Count\n",
        "book_rating_counts = train_rating_matrix.count()  # How many users rated each book\n",
        "book_weights = np.sqrt(book_rating_counts)  # More ratings = higher weight\n",
        "item_similarity_df_pearson = item_similarity_df_pearson.multiply(book_weights, axis=0)\n",
        "\n",
        "# Set K to 10\n",
        "k = 10\n",
        "\n",
        "# Run evaluation using Pearson-based similarity\n",
        "avg_rmse_pearson, avg_precision_at_k_pearson, avg_recall_at_k_pearson = evaluate_predictions(\n",
        "    test_rating_matrix, item_similarity_df_pearson, train_rating_matrix, k=k\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining collaborative filtering and content based to form a hybrid recommender system."
      ],
      "metadata": {
        "id": "tFXXnJaiZiC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OBVT-NVBZ2Lj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9NEtnjqxXvXm"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import rankdata\n",
        "\n",
        "# Compute Content-Based Similarity (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
        "item_feature_matrix = vectorizer.fit_transform(data['description'])\n",
        "\n",
        "item_similarity_content_df = pd.DataFrame(\n",
        "    cosine_similarity(item_feature_matrix),\n",
        "    index=data['title'],\n",
        "    columns=data['title']\n",
        ")\n",
        "\n",
        "# Compute Pearson-Based Collaborative Filtering Similarity\n",
        "item_similarity_df_pearson = train_rating_matrix.T.corr(method=\"pearson\").fillna(0)\n",
        "\n",
        "# Apply Truncated SVD for Dimensionality Reduction\n",
        "svd = TruncatedSVD(n_components=100, random_state=42)\n",
        "svd_matrix = svd.fit_transform(train_rating_matrix.fillna(0))\n",
        "\n",
        "# Compute Similarity on SVD Transformed Data\n",
        "svd_similarity = cosine_similarity(svd_matrix)\n",
        "svd_similarity_df = pd.DataFrame(\n",
        "    svd_similarity,\n",
        "    index=train_rating_matrix.index,\n",
        "    columns=train_rating_matrix.index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New Hybrid Recommendation Function\n",
        "def hybrid_recommend_books_svd(user_id, content_weight=0.4, cf_weight=0.4, svd_weight=0.2, num_recommendations=10):\n",
        "    if user_id not in train_rating_matrix.index:\n",
        "        return list(train_rating_matrix.count().sort_values(ascending=False).index[:num_recommendations])\n",
        "\n",
        "    # Content-Based Recommendations\n",
        "    user_rated_books = train_rating_matrix.loc[user_id].dropna().index\n",
        "    content_scores = item_similarity_content_df[user_rated_books].sum(axis=1)\n",
        "    content_based_recs = content_scores.nlargest(num_recommendations).index.tolist()\n",
        "\n",
        "    # Pearson-Based CF Recommendations\n",
        "    weighted_scores_cf = {}\n",
        "    user_ratings = train_rating_matrix.loc[user_id]\n",
        "    rated_items = user_ratings[user_ratings > 0].index\n",
        "\n",
        "    for item in rated_items:\n",
        "        if item in item_similarity_df_pearson.index:\n",
        "            similar_scores = item_similarity_df_pearson[item]\n",
        "            for similar_item, score in similar_scores.items():\n",
        "                weighted_scores_cf.setdefault(similar_item, 0)\n",
        "                weighted_scores_cf[similar_item] += score * user_ratings[item]\n",
        "\n",
        "    collaborative_recs = sorted(weighted_scores_cf.items(), key=lambda x: x[1], reverse=True)\n",
        "    collaborative_recs = [item for item, _ in collaborative_recs[:num_recommendations]]\n",
        "\n",
        "    # SVD-Based User Similarity Recommendations\n",
        "    similar_users = svd_similarity_df[user_id].nlargest(10).index.tolist()\n",
        "    svd_recs = train_rating_matrix.loc[similar_users].mean().nlargest(num_recommendations).index.tolist()\n",
        "\n",
        "    # Merge Hybrid Recommendations\n",
        "    hybrid_scores = {}\n",
        "\n",
        "    for item in content_based_recs:\n",
        "        hybrid_scores[item] = content_weight * content_scores.get(item, 0)\n",
        "\n",
        "    for item in collaborative_recs:\n",
        "        hybrid_scores[item] = hybrid_scores.get(item, 0) + cf_weight * weighted_scores_cf.get(item, 0)\n",
        "\n",
        "    for item in svd_recs:\n",
        "        hybrid_scores[item] = hybrid_scores.get(item, 0) + svd_weight\n",
        "\n",
        "    hybrid_recommendations = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    hybrid_recommendations = [item for item, _ in hybrid_recommendations[:num_recommendations]]\n",
        "\n",
        "    return hybrid_recommendations\n",
        "\n",
        "# Test the New Hybrid Model\n",
        "user_id = 1182\n",
        "hybrid_recs_svd = hybrid_recommend_books_svd(user_id, content_weight=0.4, cf_weight=0.4, svd_weight=0.2, num_recommendations=10)\n"
      ],
      "metadata": {
        "id": "YnlKg3y82MR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the hybrid recomendation system."
      ],
      "metadata": {
        "id": "9Mz8KQr1cZQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_hybrid_predictions(test_rating_matrix, item_similarity_df, train_rating_matrix, k=10):\n",
        "    rmse_scores = []\n",
        "    precision_at_k_scores = []\n",
        "    recall_at_k_scores = []\n",
        "\n",
        "    for user_id in test_rating_matrix.index:\n",
        "        user_test_ratings = test_rating_matrix.loc[user_id].dropna()\n",
        "        if user_test_ratings.empty:\n",
        "            continue\n",
        "\n",
        "        actual_items = user_test_ratings[user_test_ratings > 0].index.tolist()\n",
        "        predicted_items = hybrid_recommend_books_svd(user_id, content_weight=0.4, cf_weight=0.4, svd_weight=0.2, num_recommendations=k)\n",
        "\n",
        "        if isinstance(predicted_items, str) or len(predicted_items) == 0:\n",
        "            continue\n",
        "\n",
        "        # Calculate RMSE (Rating Prediction Accuracy)\n",
        "        actual_ratings = user_test_ratings[actual_items]\n",
        "        predicted_ratings = []\n",
        "        for item in actual_items:\n",
        "            try:\n",
        "                predicted_rating = predict_rating(user_id, item, item_similarity_df, train_rating_matrix)\n",
        "                predicted_ratings.append(predicted_rating)\n",
        "            except KeyError:\n",
        "                pass\n",
        "\n",
        "        if actual_ratings.size > 0 and len(predicted_ratings) > 0:\n",
        "            rmse = calculate_rmse(predicted_ratings, actual_ratings)\n",
        "            if not np.isnan(rmse):\n",
        "                rmse_scores.append(rmse)\n",
        "\n",
        "        # Calculate Precision@K\n",
        "        precision_at_k = calculate_precision_at_k(predicted_items, actual_items, k)\n",
        "        precision_at_k_scores.append(precision_at_k)\n",
        "\n",
        "        # Calculate Recall@K\n",
        "        recall_at_k = calculate_recall_at_k(predicted_items, actual_items, k)\n",
        "        recall_at_k_scores.append(recall_at_k)\n",
        "\n",
        "    avg_rmse = np.mean(rmse_scores) if rmse_scores else np.nan\n",
        "    avg_precision_at_k = np.mean(precision_at_k_scores) if precision_at_k_scores else np.nan\n",
        "    avg_recall_at_k = np.mean(recall_at_k_scores) if recall_at_k_scores else np.nan\n",
        "\n",
        "    return avg_rmse, avg_precision_at_k, avg_recall_at_k\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkWQlTg_MtLK",
        "outputId": "95121be9-0494-4758-b24e-93f4c9caa51b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **Evaluation Results (Hybrid Recommender, K=10):**\n",
            " **Average RMSE:** 0.2451\n",
            " **Average Precision@K:** 0.0047\n",
            " **Average Recall@K:** 0.0349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"recommend_books.pkl\", \"wb\") as file:\n",
        "    pickle.dump(hybrid_recommend_books_svd, file)\n",
        "\n",
        "#Save the hybrid function\n",
        "with open(\"hybrid_recommender_svd.pkl\", \"wb\") as file:\n",
        "    pickle.dump(hybrid_recommend_books_svd, file)"
      ],
      "metadata": {
        "id": "japDL1y_8rIO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aZLEriYOXI1"
      },
      "source": [
        "#Task: Make Predictions using the best saved model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnBLwqTJX3p0"
      },
      "source": [
        "Create a confusion Matrix and F1 score for both Models. Ensure outputs for the cells are visible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO79SOsZYG-M"
      },
      "source": [
        "Finally, Make predictions using the best model. By the time you get to this cell you may realise at some point you needed to save the model so that you cal load it later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqqe2PasUIAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35616a4-d7a5-4973-920b-4602203d7719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for User 1017: ['klb visionary kiswahili grade 4 l/b', 'klb visionary kiswahili grade 4 t/g', 'klb visionary kiswahili grade 5 l/b', 'klb visionary kiswahili grade 5 t/g', 'klb visionary kiswahili grade 6 l/b', 'klb visionary kiswahili grade 6 t/g', 'klb visionary christian religious education grade 5 l/b', 'klb visionary christian religious education grade 5 t/g', 'klb visionary christian religious education grade 6 l/b', 'klb visionary christian religious education grade 6 t/g']\n",
            "Recommendations for User 1049: ['klb visionary kiswahili grade 4 l/b', 'klb visionary kiswahili grade 4 t/g', 'klb visionary kiswahili grade 5 l/b', 'klb visionary kiswahili grade 5 t/g', 'klb visionary kiswahili grade 6 l/b', 'klb visionary kiswahili grade 6 t/g', 'klb visionary christian religious education grade 5 l/b', 'klb visionary christian religious education grade 5 t/g', 'klb visionary christian religious education grade 6 l/b', 'klb visionary christian religious education grade 6 t/g']\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/hybrid_recommender_svd.pkl\"\n",
        "user_ids = 1017, 1049\n",
        "\n",
        "def make_predictions(model_path, user_ids, num_recommendations=5):\n",
        "\n",
        "    # Load the model\n",
        "    with open(model_path, \"rb\") as file:\n",
        "        hybrid_recommender = pickle.load(file)\n",
        "    # Make predictions\n",
        "    recommendations = {}\n",
        "    for user_id in user_ids:\n",
        "        recommendations[user_id] = hybrid_recommender(user_id, num_recommendations)\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Run the predictions\n",
        "predictions = make_predictions(model_path, user_ids)\n",
        "\n",
        "# Print the results\n",
        "for user, recs in predictions.items():\n",
        "    print(f\"Recommendations for User {user}: {recs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfTHk2nZMzTH"
      },
      "source": [
        "Congratulations!!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}